import json
import uuid
from typing import List, Dict, Optional, Any
from datetime import datetime
import os
from qdrant_client import QdrantClient
from qdrant_client.models import Distance, VectorParams, PointStruct
import dashscope
from dashscope import Generation

# å¯¼å…¥promptæ¨¡å—
from .prompts import FACT_EXTRACTION_PROMPT, MEMORY_PROCESSING_PROMPT
# å¯¼å…¥é€‚é…å™¨ï¼ˆTinyMem0ç‰¹å®šï¼‰
from .adapters import extract_llm_response_content, call_llm_with_prompt, handle_llm_error, extract_embedding_from_response

# å¯¼å…¥æ¨ç†å·¥å…· - æ·»åŠ çˆ¶ç›®å½•åˆ°è·¯å¾„
import sys
from pathlib import Path
_project_root = Path(__file__).parent.parent.parent
if str(_project_root) not in sys.path:
    sys.path.insert(0, str(_project_root))
from utils.inference import parse_json_response

class MemorySystem:
    def __init__(
        self,
        collection_name: str = "memories",
        llm_model: str = "qwen-turbo",
        embedding_model: str = "text-embedding-v1",
        log_mode: Optional[str] = None,
        log_level: Optional[str] = None,
        log_file: Optional[str] = None,
        qdrant_path: Optional[str] = None,
        use_local_llm: Optional[bool] = None,
        local_model_path: Optional[str] = None,
        local_embedding_model: Optional[str] = None,
        embedding_dim: Optional[int] = None
    ):
        """
        åˆå§‹åŒ–è®°å¿†ç³»ç»Ÿ
        
        Args:
            collection_name: Qdranté›†åˆåç§°
            llm_model: LLMæ¨¡å‹åç§°ï¼ˆäº‘ç«¯APIï¼‰
            embedding_model: å‘é‡æ¨¡å‹åç§°ï¼ˆäº‘ç«¯APIï¼‰
            log_mode: æ—¥å¿—æ¨¡å¼ (plain | json)
            log_level: æ—¥å¿—çº§åˆ« (debug | info | warn | error)
            log_file: æ—¥å¿—æ–‡ä»¶è·¯å¾„
            qdrant_path: Qdrantæ•°æ®å­˜å‚¨è·¯å¾„
            use_local_llm: æ˜¯å¦ä½¿ç”¨æœ¬åœ°LLM
            local_model_path: æœ¬åœ°LLMè·¯å¾„
            local_embedding_model: æœ¬åœ°åµŒå…¥æ¨¡å‹
            embedding_dim: åµŒå…¥å‘é‡ç»´åº¦
        """
        self.collection_name = collection_name
        self.qdrant_path = qdrant_path or "./qdrant_data"
        self.llm_model = llm_model
        self.embedding_model = embedding_model
        
        # å‚æ•°ä¼˜å…ˆçº§ï¼šæ„é€ å‚æ•° > é»˜è®¤å€¼ï¼ˆä¸å†è¯»å–.envï¼‰
        self.use_local_llm = use_local_llm if use_local_llm is not None else False
        self.local_model_path = local_model_path or ""
        self.local_embedding_model = local_embedding_model or "BAAI/bge-small-zh-v1.5"
        self.embedding_dim = embedding_dim or (512 if self.use_local_llm else 1536)
        # æ—¥å¿—æ¨¡å¼: ä¼˜å…ˆå‚æ•°ï¼Œå…¶æ¬¡ç¯å¢ƒå˜é‡ï¼Œé»˜è®¤ plain
        self.log_mode = (log_mode or os.getenv("MEM_LOG_MODE") or "plain").lower()
        if self.log_mode not in {"plain", "json"}:
            self.log_mode = "plain"
        # æ—¥å¿—çº§åˆ«: DEBUG < INFO < WARN < ERROR
        self._level_order = {"debug":10, "info":20, "warn":30, "error":40}
        env_level = (os.getenv("MEM_LOG_LEVEL") or "").lower()
        self.log_level = (log_level or env_level or "info").lower()
        if self.log_level not in self._level_order:
            self.log_level = "info"
        # æ—¥å¿—æ–‡ä»¶
        self.log_file = log_file or os.getenv("MEM_LOG_FILE")
        if self.log_file:
            # è‹¥åŒ…å«ç›®å½•åˆ™åˆ›å»º
            log_dir = os.path.dirname(self.log_file)
            if log_dir and not os.path.exists(log_dir):
                try:
                    os.makedirs(log_dir, exist_ok=True)
                except Exception as e:
                    # åˆ›å»ºå¤±è´¥åˆ™æ”¾å¼ƒæ–‡ä»¶å†™å…¥
                    self.log_file = None
                    print(f"[MEMORY_SYSTEM] æ— æ³•åˆ›å»ºæ—¥å¿—ç›®å½• {log_dir}: {e}")
        
        # åˆå§‹åŒ–Qdrantå®¢æˆ·ç«¯ï¼Œä½¿ç”¨æœ¬åœ°æ–‡ä»¶å­˜å‚¨
        self.qdrant_client = QdrantClient(path=self.qdrant_path)
        
        # è®¾ç½®APIå¯†é’¥
        dashscope.api_key = os.getenv("DASHSCOPE_API_KEY")
        
        # åˆå§‹åŒ–é›†åˆ
        self._init_collection()
    
    def _init_collection(self):
        """åˆå§‹åŒ–Qdranté›†åˆ"""
        collections = self.qdrant_client.get_collections()
        collection_names = [col.name for col in collections.collections]
        
        if self.collection_name not in collection_names:
            # ä½¿ç”¨å®ä¾‹çš„embedding_dim
            vector_size = self.embedding_dim
            
            # åˆ›å»ºæ–°é›†åˆ
            self.qdrant_client.create_collection(
                collection_name=self.collection_name,
                vectors_config=VectorParams(size=vector_size, distance=Distance.COSINE)
            )
            self._log_event("init", message=f"åˆ›å»ºé›†åˆ: {self.collection_name}, å‘é‡ç»´åº¦: {vector_size}", level="info")
        else:
            self._log_event("init", message=f"ä½¿ç”¨ç°æœ‰é›†åˆ: {self.collection_name}", level="info")

    
    def extract_facts(self, conversation: str) -> List[str]:
        """
        ä»å¯¹è¯ä¸­æå–äº‹å®ä¿¡æ¯
        
        Args:
            conversation: ç”¨æˆ·å¯¹è¯å†…å®¹
            
        Returns:
            æå–çš„äº‹å®åˆ—è¡¨
        """
        self._log_event("facts_extract_start", level="debug")
        
        if self.use_local_llm:
            # ä½¿ç”¨æœ¬åœ°LLM
            from utils.inference import call_local_llm
            result = call_local_llm(
                model_path=self.local_model_path,
                system_prompt=FACT_EXTRACTION_PROMPT,
                user_prompt=conversation
            )
        else:
            # ä½¿ç”¨äº‘ç«¯API
            result = call_llm_with_prompt(self.llm_model, FACT_EXTRACTION_PROMPT, conversation)
        
        if result:
            parsed = parse_json_response(result, 'facts')
            # ç¡®ä¿è¿”å›çš„æ˜¯åˆ—è¡¨
            if isinstance(parsed, list):
                return parsed
        return []
     
    
    def get_embeddings(self, text: str, operation: str = "search") -> List[float]:
        """
        è·å–æ–‡æœ¬çš„å‘é‡åµŒå…¥
        æ”¯æŒé˜¿é‡Œäº‘APIå’Œæœ¬åœ°åµŒå…¥æ¨¡å‹
        
        Args:
            text: è¾“å…¥æ–‡æœ¬
            operation: æ“ä½œç±»å‹ ("search" æˆ– "add")
            
        Returns:
            å‘é‡åµŒå…¥
        """
        if self.use_local_llm:
            try:
                from sentence_transformers import SentenceTransformer
                # ä½¿ç”¨å…¨å±€åµŒå…¥æ¨¡å‹å®ä¾‹
                if not hasattr(self, '_embedding_model_instance'):
                    model_name = self.local_embedding_model
                    
                    # æ£€æŸ¥æ˜¯å¦æ˜¯æœ¬åœ°è·¯å¾„
                    if os.path.exists(model_name):
                        self._log_event("loading_embedding_model", model=model_name, level="info")
                        self._embedding_model_instance = SentenceTransformer(model_name)
                    else:
                        # ä»HuggingFaceä¸‹è½½åˆ°å›ºå®šç›®å½•
                        embedding_cache_dir = "./models/embeddings"
                        self._log_event("loading_embedding_model", model=model_name, level="info")
                        print(f"æ­£åœ¨åŠ è½½åµŒå…¥æ¨¡å‹: {model_name}")
                        print(f"ğŸ“ ä¿å­˜åˆ°: {embedding_cache_dir}")
                        os.makedirs(embedding_cache_dir, exist_ok=True)
                        self._embedding_model_instance = SentenceTransformer(
                            model_name, 
                            cache_folder=embedding_cache_dir
                        )
                
                self._log_event("embedding_start", level="debug", op=operation)
                embedding = self._embedding_model_instance.encode(text, normalize_embeddings=True)
                emb = embedding.tolist()
                self._log_event("embedding_ok", level="debug", size=len(emb))
                return emb
            except Exception as e:
                self._log_event("embedding_error", error=str(e), level="error")
                return []
        else:
            # ä½¿ç”¨é˜¿é‡Œäº‘API
            try:
                self._log_event("embedding_start", level="debug", op=operation)
                response = dashscope.TextEmbedding.call(
                    model=self.embedding_model,
                    input=text
                )
                emb = extract_embedding_from_response(response)
                self._log_event("embedding_ok", level="debug", size=len(emb) if emb else 0)
                return emb
            except Exception as e:
                self._log_event("embedding_error", error=str(e), level="error")
                return []
    
    def search_memories(self, query: str, filters: Optional[Dict] = None, 
                       limit: int = 5, threshold: Optional[float] = None) -> List[Dict]:
        """
        æœç´¢ç›¸å…³è®°å¿†
        
        Args:
            query: æœç´¢æŸ¥è¯¢
            filters: è¿‡æ»¤æ¡ä»¶
            limit: è¿”å›ç»“æœæ•°é‡é™åˆ¶
            threshold: ç›¸ä¼¼åº¦é˜ˆå€¼
            
        Returns:
            ç›¸å…³è®°å¿†åˆ—è¡¨
        """
        try:
            self._log_event("search_start", query=query, level="debug")
            embeddings = self.get_embeddings(query, "search")
            if not embeddings:
                return []
            
            # æ„å»ºQdrantè¿‡æ»¤å™¨
            query_filter = None
            if filters:
                from qdrant_client.models import Filter, FieldCondition, MatchValue
                conditions = []
                for key, value in filters.items():
                    if value is None:
                        continue
                    conditions.append(FieldCondition(key=f"metadata.{key}", match=MatchValue(value=value)))
                query_filter = Filter(must=conditions)
            
            # æ‰§è¡Œå‘é‡æœç´¢
            search_result = self.qdrant_client.search(
                collection_name=self.collection_name,
                query_vector=embeddings,
                limit=limit,
                query_filter=query_filter,
                score_threshold=threshold
            )
            
            memories = []
            for result in search_result:
                # ç±»å‹å®ˆå«ï¼šç¡®ä¿ payload ä¸ä¸º None
                if result.payload is not None:
                    memories.append({
                        "id": result.id,
                        "text": result.payload.get("data", ""),
                        "score": result.score,
                        "metadata": result.payload.get("metadata", {})
                    })
            
            self._log_event("search_ok", query=query, result_count=len(memories), level="debug")
            return memories
        except Exception as e:
            self._log_event("search_error", error=str(e), level="error")
            return []
    
    def process_memory(self, new_facts: List[str], existing_memories: List[Dict]) -> List[Dict]:
        """
        å¤„ç†è®°å¿†ï¼Œå†³å®šæ·»åŠ ã€æ›´æ–°ã€åˆ é™¤æˆ–ä¸åšæ“ä½œ
        
        Args:
            new_facts: æ–°æå–çš„äº‹å®
            existing_memories: ç°æœ‰è®°å¿†
            
        Returns:
            å¤„ç†åçš„è®°å¿†åˆ—è¡¨
        """
        try:
            # å‡†å¤‡è¾“å…¥æ•°æ®
            input_data = {
                "new_facts": new_facts,
                "existing_memories": existing_memories
            }
            
            if self.use_local_llm:
                # ä½¿ç”¨æœ¬åœ°LLM
                from utils.inference import call_local_llm
                result = call_local_llm(
                    model_path=self.local_model_path,
                    system_prompt=MEMORY_PROCESSING_PROMPT,
                    user_prompt=json.dumps(input_data, ensure_ascii=False)
                )
            else:
                # ä½¿ç”¨äº‘ç«¯API
                result = call_llm_with_prompt(
                    self.llm_model, 
                    MEMORY_PROCESSING_PROMPT, 
                    json.dumps(input_data, ensure_ascii=False)
                )
            
            if result:
                parsed = parse_json_response(result, 'memory')
                # ç¡®ä¿è¿”å›çš„æ˜¯åˆ—è¡¨
                if isinstance(parsed, list):
                    return parsed
            return []
        except Exception as e:
            self._log_event("process_error", error=str(e), level="error")
            return []
    
    def add_memory(self, text: str, metadata: Optional[Dict] = None) -> str:
        """
        æ·»åŠ æ–°è®°å¿†
        
        Args:
            text: è®°å¿†å†…å®¹
            metadata: å…ƒæ•°æ®
            
        Returns:
            è®°å¿†ID
        """
        try:
            embeddings = self.get_embeddings(text, "add")
            if not embeddings:
                return ""
            
            memory_id = str(uuid.uuid4())
            point = PointStruct(
                id=memory_id,
                vector=embeddings,
                payload={
                    "data": text,
                    "metadata": metadata or {},
                    "created_at": datetime.now().isoformat()
                }
            )
            
            self.qdrant_client.upsert(
                collection_name=self.collection_name,
                points=[point]
            )
            
            return memory_id
        except Exception as e:
            self._log_event("add_error", error=str(e), level="error")
            return ""
    
    def update_memory(self, memory_id: str, new_text: str, metadata: Optional[Dict] = None):
        """
        æ›´æ–°è®°å¿†
        
        Args:
            memory_id: è®°å¿†ID
            new_text: æ–°çš„è®°å¿†å†…å®¹
            metadata: æ–°çš„å…ƒæ•°æ®
        """
        try:
            embeddings = self.get_embeddings(new_text, "add")
            if not embeddings:
                return
            
            point = PointStruct(
                id=memory_id,
                vector=embeddings,
                payload={
                    "data": new_text,
                    "metadata": metadata or {},
                    "updated_at": datetime.now().isoformat()
                }
            )
            
            self.qdrant_client.upsert(
                collection_name=self.collection_name,
                points=[point]
            )
        except Exception as e:
            self._log_event("update_error", error=str(e), level="error")
    
    def delete_memory(self, memory_id: str):
        """
        åˆ é™¤è®°å¿†
        
        Args:
            memory_id: è®°å¿†ID
        """
        try:
            self.qdrant_client.delete(
                collection_name=self.collection_name,
                points_selector=[memory_id]
            )
        except Exception as e:
            self._log_event("delete_error", error=str(e), level="error")
    
    def write_memory(self, conversation: str, user_id: Optional[str] = None, agent_id: Optional[str] = None, extra_metadata: Optional[Dict] = None):
        """
        è®°å¿†å†™å…¥ä¸»æµç¨‹
        
        Args:
            conversation: ç”¨æˆ·å¯¹è¯
            user_id: ç”¨æˆ·ID
            agent_id: ä»£ç†ID
            extra_metadata: é¢å¤–çš„metadataä¿¡æ¯ï¼ˆå¦‚session_id, dialog_idç­‰ï¼‰
        """
        # 1. æå–äº‹å®
        new_facts = self.extract_facts(conversation)
        if not new_facts:
            self._log_event("facts_none", message="æœªæå–åˆ°ç›¸å…³äº‹å®", level="info")
            return
        self._log_event("facts_extracted", facts=new_facts, level="info")
        
        # 2. æ£€ç´¢ç›¸å…³è®°å¿†ï¼ˆå»é‡æ”¶é›†ï¼‰
        retrieved_old_memory_map: Dict[str, Dict[str, str]] = {}
        for new_fact in new_facts:
            filters = {}
            if user_id:
                filters["user_id"] = user_id
            if agent_id:
                filters["agent_id"] = agent_id
            existing_memories = self.search_memories(query=new_fact, filters=filters, limit=5)
            for mem in existing_memories:
                # ä»¥ id ä½œä¸ºå”¯ä¸€é”®ï¼Œé¿å…é‡å¤åŠ å…¥
                retrieved_old_memory_map[mem["id"]] = {"id": mem["id"], "text": mem["text"]}
        retrieved_old_memory = list(retrieved_old_memory_map.values())
        self._log_event("memories_retrieved", memories=retrieved_old_memory, level="debug")

        # 3. å¤„ç†è®°å¿†ï¼ˆLLM è¿”å›åè¿›è¡Œäº‹ä»¶å½’ä¸€åŒ–ï¼‰
        processed_memories_raw = self.process_memory(new_facts, retrieved_old_memory)
        processed_memories = self._normalize_events(processed_memories_raw)
        if processed_memories_raw and len(processed_memories_raw) != len(processed_memories):
            self._log_event(
                "events_normalized",
                raw_count=len(processed_memories_raw),
                normalized_count=len(processed_memories),
                level="debug"
            )

        # 4. æ‰§è¡Œè®°å¿†æ“ä½œï¼ˆæŒ‰å½’ä¸€åŒ–ç»“æœï¼‰
        for memory in processed_memories:
            event = memory.get("event", "NONE")
            memory_id = memory.get("id")
            text = memory.get("text")
            
            metadata = {
                "user_id": user_id,
                "agent_id": agent_id,
                "created_at": datetime.now().isoformat()
            }
            # åˆå¹¶é¢å¤–metadata
            if extra_metadata:
                metadata.update(extra_metadata)
            
            if event == "ADD":
                # ç±»å‹å®ˆå«ï¼šç¡®ä¿ text ä¸ä¸º None
                if text:
                    self.add_memory(text, metadata)
                    self._log_event("memory_add", text=text, metadata=metadata, level="info")
            elif event == "UPDATE":
                # ç±»å‹å®ˆå«ï¼šç¡®ä¿ memory_id å’Œ text ä¸ä¸º None
                if memory_id and text:
                    self.update_memory(memory_id, text, metadata)
                    self._log_event("memory_update", id=memory_id, text=text, metadata=metadata, level="info")
            elif event == "DELETE":
                # ç±»å‹å®ˆå«ï¼šç¡®ä¿ memory_id ä¸ä¸º None
                if memory_id:
                    self.delete_memory(memory_id)
                    self._log_event("memory_delete", id=memory_id, text=text, level="info")
            elif event == "NONE":
                self._log_event("memory_none", id=memory_id, text=text, level="debug")
    
    def search_memory(self, query: str, user_id: Optional[str] = None, agent_id: Optional[str] = None, limit: int = 5) -> List[Dict]:
        """
        è®°å¿†æœç´¢
        
        Args:
            query: æœç´¢æŸ¥è¯¢
            user_id: ç”¨æˆ·ID
            agent_id: ä»£ç†ID
            limit: è¿”å›ç»“æœæ•°é‡
            
        Returns:
            ç›¸å…³è®°å¿†åˆ—è¡¨
        """
        # æ„å»ºè¿‡æ»¤æ¡ä»¶
        filters = {}
        if user_id:
            filters["user_id"] = user_id
        if agent_id:
            filters["agent_id"] = agent_id
        
        return self.search_memories(query, filters, limit) 

    # ================= å†…éƒ¨å·¥å…·æ–¹æ³• =================
    def _normalize_events(self, memories: List[Dict]) -> List[Dict]:
        """å¯¹ LLM è¿”å›çš„ memory äº‹ä»¶ç»“æœè¿›è¡Œå½’ä¸€åŒ–ä¸å»é‡ã€‚

        è§„åˆ™ï¼š
        1. åŒä¸€ä¸ª id åªä¿ç•™ä¼˜å…ˆçº§æœ€é«˜çš„äº‹ä»¶ï¼ˆDELETE > UPDATE > ADD > NONEï¼‰
        2. å¤šä¸ª ADD å¦‚ text å®Œå…¨ç›¸åŒï¼Œåˆ™ä»…ä¿ç•™ä¸€æ¡
        3. NONE äº‹ä»¶å¦‚æœä¸å…¶å®ƒäº‹ä»¶å†²çªï¼ˆåŒ id å·²æœ‰æ›´é«˜ä¼˜å…ˆçº§ï¼‰ï¼Œä¼šè¢«ä¸¢å¼ƒ
        4. ä¿æŒè¾“å‡ºçš„äº‹ä»¶åˆ—è¡¨é¡ºåºå°½é‡ç¨³å®šï¼šå…ˆä¿ç•™å»é‡åçš„ ADDï¼Œå…¶ä½™æŒ‰å‡ºç°é¡ºåºåˆå¹¶
        """
        if not memories:
            return []

        priority = {"DELETE": 4, "UPDATE": 3, "ADD": 2, "NONE": 1}
        by_id: Dict[str, Dict] = {}
        add_seen_text = set()
        result_adds: List[Dict] = []

        ordered_non_add_ids = []  # è®°å½•é ADD äº‹ä»¶çš„ id é¡ºåºç”¨äºç¨³å®šè¾“å‡º

        for m in memories:
            event = m.get("event", "NONE")
            mid = m.get("id")
            text = m.get("text")

            # å¤„ç† ADDï¼šç”¨ text å»é‡ï¼ˆæ²¡æœ‰ id æˆ–è€… id æ˜¯æ–°ç”Ÿæˆçš„å ä½ï¼‰
            if event == "ADD":
                if text in add_seen_text:
                    continue
                add_seen_text.add(text)
                result_adds.append(m)
                continue

            # å¤„ç†æœ‰ id çš„å…¶å®ƒäº‹ä»¶
            if mid:
                prev = by_id.get(mid)
                if (not prev) or priority.get(event, 0) > priority.get(prev["__event"], 0):
                    by_id[mid] = {**m, "__event": event}
                    if mid not in ordered_non_add_ids:
                        ordered_non_add_ids.append(mid)
            # æ²¡æœ‰ id ä¸”ä¸æ˜¯ ADD çš„ NONE/UPDATE/DELETEï¼ˆä¸åˆæ³•ï¼‰ï¼Œå¿½ç•¥

        # æ±‡æ€»ï¼šå…ˆ ADDï¼Œå†æŒ‰ id é¡ºåºè¾“å‡ºå…¶å®ƒäº‹ä»¶
        normalized = list(result_adds)
        for mid in ordered_non_add_ids:
            item = by_id[mid]
            item.pop("__event", None)
            normalized.append(item)

        return normalized

    def _log_event(self, event: str, level: str = "info", **data):
        """ç»Ÿä¸€æ—¥å¿—è¾“å‡ºã€‚

        plain è¾“å‡ºï¼šç®€å•çš„äººç±»å¯è¯»å½¢å¼ã€‚
        json  è¾“å‡ºï¼šä¸€è¡Œ JSONï¼ŒåŒ…å«æ—¶é—´æˆ³ä¸äº‹ä»¶åã€‚
        """
        level = (level or "info").lower()
        if level not in self._level_order:
            level = "info"
        # çº§åˆ«è¿‡æ»¤
        if self._level_order[level] < self._level_order.get(self.log_level, 20):
            return
        timestamp = datetime.now().isoformat()
        # ç”Ÿæˆæ¶ˆæ¯
        if self.log_mode == "json":
            payload = {"ts": timestamp, "event": event, "level": level.upper(), **data}
            try:
                line = json.dumps(payload, ensure_ascii=False)
            except Exception as e:
                line = f"{{'ts':'{timestamp}','event':'{event}','level':'{level.upper()}','error':'log_json_fail','detail':'{e}'}}"
        else:
            base = f"[{level.upper()}][{event}]"
            if "message" in data:
                base += f" {data['message']}"
            if "text" in data and event not in {"facts_extracted", "memories_retrieved"}:
                base += f" | text={data['text']}"
            if event == "facts_extracted":
                base += f" æå–åˆ°çš„äº‹å®: {data.get('facts')}"
            elif event == "memories_retrieved":
                base += f" ç›¸å…³è®°å¿†: {data.get('memories')}"
            elif event == "events_normalized":
                base += f" äº‹ä»¶å½’ä¸€åŒ–: {data.get('raw_count')} -> {data.get('normalized_count')}"
            elif event.startswith("memory_"):
                if "id" in data:
                    base += f" | id={data['id']}"
            if "error" in data:
                base += f" | ERROR={data['error']}"
            line = base
        # æ§åˆ¶å°è¾“å‡º
        print(line)
        # æ–‡ä»¶è¾“å‡º
        if self.log_file:
            try:
                with open(self.log_file, 'a', encoding='utf-8') as f:
                    f.write(line + '\n')
            except Exception:
                pass
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
è®°å¿†ç³»ç»Ÿä½¿ç”¨ç¤ºä¾‹ - è‡ªåŠ¨ä¸‹è½½æ¨¡å‹å¹¶è¿è¡Œ
"""
import sys
import os
import argparse
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root / 'src'))
sys.path.insert(0, str(project_root))

from dotenv import load_dotenv
load_dotenv()
from tinymem0 import MemorySystem


def download_models(model_shortcut='qwen2.5-7b', model_format='gguf'):
    """è‡ªåŠ¨ä¸‹è½½æ¨¡å‹
    
    Args:
        model_shortcut: æ¨¡å‹å¿«æ·åç§° (qwen2.5-7b, mistral-7bç­‰)
        model_format: æ¨¡å‹æ ¼å¼ (ggufæˆ–safetensors)
    """
    print("=" * 70)
    print("ğŸ“¦ æ£€æŸ¥å¹¶ä¸‹è½½æ¨¡å‹")
    print("=" * 70)
    
    # æ£€æŸ¥åµŒå…¥æ¨¡å‹
    print("\n1ï¸âƒ£ åµŒå…¥æ¨¡å‹...")
    embedding_model = os.getenv("LOCAL_EMBEDDING_MODEL", "BAAI/bge-small-zh-v1.5")
    print(f"   {embedding_model} (é¦–æ¬¡ä½¿ç”¨æ—¶è‡ªåŠ¨ä¸‹è½½)")
    
    # æ£€æŸ¥LLMæ¨¡å‹
    print("\n2ï¸âƒ£ LLMæ¨¡å‹...")
    use_local = os.getenv("USE_LOCAL_LLM", "false").lower() == "true"
    
    if not use_local:
        print("   â­ï¸  äº‘ç«¯APIæ¨¡å¼ï¼Œæ— éœ€ä¸‹è½½")
        print("\n" + "=" * 70)
        return
    
    # æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²å­˜åœ¨
    if model_format == 'gguf':
        model_dir = Path('./models/gguf')
        if model_dir.exists():
            gguf_files = list(model_dir.glob('*.gguf'))
            if gguf_files:
                print(f"   âœ… æ¨¡å‹å·²å­˜åœ¨: {gguf_files[0]}")
                print("\n" + "=" * 70)
                return
    else:
        model_dir = Path('./models/safetensors') / model_shortcut
        if model_dir.exists() and list(model_dir.glob('*')):
            print(f"   âœ… æ¨¡å‹å·²å­˜åœ¨: {model_dir}")
            print("\n" + "=" * 70)
            return
    
    # æ¨¡å‹ä¸å­˜åœ¨ï¼Œè°ƒç”¨ä¸‹è½½å·¥å…·
    print(f"   âŒ æ¨¡å‹ä¸å­˜åœ¨ï¼Œå‡†å¤‡ä¸‹è½½...\n")
    
    # æ·»åŠ scriptsåˆ°è·¯å¾„å¹¶è°ƒç”¨ä¸‹è½½å‡½æ•°
    sys.path.insert(0, str(Path(__file__).parent.parent / 'scripts'))
    from download_llm import download_model_with_shortcut
    
    try:
        downloaded_path = download_model_with_shortcut(
            model_shortcut=model_shortcut,
            model_format=model_format,
            quantization='Q4_K_M',
            verbose=True
        )
        
        print(f"\n   âœ… æ¨¡å‹ä¸‹è½½å®Œæˆï¼")
        print(f"   ğŸ“‚ ä½ç½®: {downloaded_path}")
        
    except Exception as e:
        print(f"\n   âŒ ä¸‹è½½å¤±è´¥: {e}")
        print(f"   ğŸ’¡ ä½ å¯ä»¥æ‰‹åŠ¨è¿è¡Œ:")
        print(f"   python scripts/download_llm.py --model {model_shortcut} --format {model_format}")
    
    print("\n" + "=" * 70)


def main():
    """ä¸»å‡½æ•° - æ¼”ç¤ºè®°å¿†ç³»ç»Ÿçš„ä½¿ç”¨"""
    import os 
    use_local = os.getenv("USE_LOCAL_LLM", "false").lower() == "true"
    if not use_local and not os.getenv("DASHSCOPE_API_KEY"):
        raise RuntimeError("æœªæ‰¾åˆ° DASHSCOPE_API_KEYï¼Œè¯·åœ¨ .env ä¸­é…ç½®ã€‚")
    
    mode = "æœ¬åœ°æ¨¡å‹" if use_local else "äº‘ç«¯API"
    print(f"åˆå§‹åŒ–è®°å¿†ç³»ç»Ÿ ({mode})...")
    memory_system = MemorySystem()
    
    # ç¤ºä¾‹1: å†™å…¥è®°å¿†
    print("\n=== ç¤ºä¾‹1: å†™å…¥è®°å¿† ===")
    conversation1 = "ä½ å¥½ï¼Œæˆ‘å«å¼ ä¸‰ï¼Œæ˜¯ä¸€åè½¯ä»¶å·¥ç¨‹å¸ˆï¼Œæˆ‘å–œæ¬¢çœ‹ç”µå½±ï¼Œç‰¹åˆ«æ˜¯ç§‘å¹»ç‰‡ã€‚"
    print(f"ç”¨æˆ·å¯¹è¯: {conversation1}")
    
    memory_system.write_memory(
        conversation=conversation1,
        user_id="user_001",
        agent_id="agent_001"
    )
    
    # ç¤ºä¾‹2: æœç´¢è®°å¿†
    print("\n=== ç¤ºä¾‹2: æœç´¢è®°å¿† ===")
    query = "å¼ ä¸‰çš„èŒä¸šæ˜¯ä»€ä¹ˆï¼Ÿ"
    print(f"æœç´¢æŸ¥è¯¢: {query}")
    
    results = memory_system.search_memory(
        query=query,
        user_id="user_001",
        agent_id="agent_001",
        limit=3
    )
    
    print("æœç´¢ç»“æœ:")
    for i, result in enumerate(results, 1):
        print(f"{i}. {result['text']} (ç›¸ä¼¼åº¦: {result['score']:.3f})")
    
    # ç¤ºä¾‹3: æ›´æ–°è®°å¿†
    print("\n=== ç¤ºä¾‹3: æ›´æ–°è®°å¿† ===")
    conversation2 = "æˆ‘æœ€è¿‘æ”¹å˜äº†èŒä¸šï¼Œç°åœ¨æ˜¯ä¸€åäº§å“ç»ç†ï¼Œä¸å†åšè½¯ä»¶å·¥ç¨‹å¸ˆäº†ã€‚"
    print(f"ç”¨æˆ·å¯¹è¯: {conversation2}")
    
    memory_system.write_memory(
        conversation=conversation2,
        user_id="user_001",
        agent_id="agent_001"
    )
    
    # å†æ¬¡æœç´¢éªŒè¯æ›´æ–°
    print("\næ›´æ–°åå†æ¬¡æœç´¢:")
    results = memory_system.search_memory(
        query="å¼ ä¸‰çš„èŒä¸š",
        user_id="user_001",
        agent_id="agent_001",
        limit=3
    )
    
    print("æœç´¢ç»“æœ:")
    for i, result in enumerate(results, 1):
        print(f"{i}. {result['text']} (ç›¸ä¼¼åº¦: {result['score']:.3f})")


def example_memory_update():
    """ç¤ºä¾‹2: è®°å¿†æ›´æ–°å’Œå†²çªå¤„ç†"""
    print("\n" + "=" * 70)
    print("ğŸ”„ ç¤ºä¾‹2: è®°å¿†æ›´æ–°")
    print("=" * 70)
    
    memory = MemorySystem(collection_name="demo_update")
    
    # åˆå§‹è®°å¿†
    print("\n1ï¸âƒ£ å†™å…¥åˆå§‹ä¿¡æ¯...")
    memory.write_memory(
        "æˆ‘å«ææ˜ï¼Œä»Šå¹´25å²ï¼Œåœ¨ä¸Šæµ·åšäº§å“ç»ç†",
        user_id="user_li",
        agent_id="assistant"
    )
    print("âœ… åˆå§‹è®°å¿†å·²ä¿å­˜")
    
    # æœç´¢å½“å‰èŒä¸š
    print("\n2ï¸âƒ£ æŸ¥è¯¢å½“å‰èŒä¸š...")
    results = memory.search_memory(
        "ææ˜çš„èŒä¸š",
        user_id="user_li",
        limit=1
    )
    if results:
        print(f"  å½“å‰èŒä¸š: {results[0]['text']}")
    
    # æ›´æ–°ä¿¡æ¯
    print("\n3ï¸âƒ£ æ›´æ–°èŒä¸šä¿¡æ¯...")
    memory.write_memory(
        "æˆ‘ç°åœ¨æ¢å·¥ä½œäº†ï¼Œæˆä¸ºäº†ä¸€åæ•°æ®ç§‘å­¦å®¶",
        user_id="user_li",
        agent_id="assistant"
    )
    print("âœ… è®°å¿†å·²æ›´æ–°")
    
    # å†æ¬¡æœç´¢
    print("\n4ï¸âƒ£ éªŒè¯æ›´æ–°ç»“æœ...")
    results = memory.search_memory(
        "ææ˜çš„èŒä¸š",
        user_id="user_li",
        limit=2
    )
    
    print("  æœç´¢ç»“æœ:")
    for i, result in enumerate(results, 1):
        print(f"    {i}. {result['text']}")
    
    print("\nâœ… ç¤ºä¾‹2å®Œæˆ")


def example_multi_user():
    """ç¤ºä¾‹3: å¤šç”¨æˆ·è®°å¿†éš”ç¦»"""
    print("\n" + "=" * 70)
    print("ğŸ‘¥ ç¤ºä¾‹3: å¤šç”¨æˆ·åœºæ™¯")
    print("=" * 70)
    
    memory = MemorySystem(collection_name="demo_multiuser")
    
    # ç”¨æˆ·Açš„è®°å¿†
    print("\n1ï¸âƒ£ ç”¨æˆ·Açš„å¯¹è¯...")
    memory.write_memory(
        "æˆ‘å–œæ¬¢åƒå·èœï¼Œç‰¹åˆ«æ˜¯éº»å©†è±†è…",
        user_id="user_a",
        agent_id="assistant"
    )
    
    # ç”¨æˆ·Bçš„è®°å¿†
    print("2ï¸âƒ£ ç”¨æˆ·Bçš„å¯¹è¯...")
    memory.write_memory(
        "æˆ‘å–œæ¬¢åƒç²¤èœï¼Œç‰¹åˆ«æ˜¯ç™½åˆ‡é¸¡",
        user_id="user_b",
        agent_id="assistant"
    )
    
    # åˆ†åˆ«æœç´¢
    print("\n3ï¸âƒ£ åˆ†åˆ«æœç´¢ç”¨æˆ·åå¥½...")
    
    print("  ç”¨æˆ·Açš„æœç´¢ç»“æœ:")
    results_a = memory.search_memory(
        "å–œæ¬¢åƒä»€ä¹ˆèœ",
        user_id="user_a",
        limit=1
    )
    for r in results_a:
        print(f"    - {r['text']}")
    
    print("  ç”¨æˆ·Bçš„æœç´¢ç»“æœ:")
    results_b = memory.search_memory(
        "å–œæ¬¢åƒä»€ä¹ˆèœ",
        user_id="user_b",
        limit=1
    )
    for r in results_b:
        print(f"    - {r['text']}")
    
    print("\nâœ… ç¤ºä¾‹3å®Œæˆ - è®°å¿†å·²æ­£ç¡®éš”ç¦»")


def example_fact_extraction():
    """ç¤ºä¾‹4: äº‹å®æå–åŠŸèƒ½"""
    print("\n" + "=" * 70)
    print("ğŸ“Š ç¤ºä¾‹4: äº‹å®æå–")
    print("=" * 70)
    
    memory = MemorySystem(collection_name="demo_facts")
    
    # æµ‹è¯•ä¸åŒç±»å‹çš„å¯¹è¯
    test_cases = [
        ("ç®€å•é—®å€™", "ä½ å¥½"),
        ("ä¸ªäººä¿¡æ¯", "æˆ‘å«ç‹èŠ³ï¼Œä»Šå¹´30å²ï¼Œä½åœ¨æ·±åœ³"),
        ("å…´è¶£çˆ±å¥½", "æˆ‘å–œæ¬¢æ—…æ¸¸ï¼Œå»å¹´å»äº†æ—¥æœ¬å’ŒéŸ©å›½"),
        ("å·¥ä½œä¿¡æ¯", "æˆ‘åœ¨ä¸€å®¶äº’è”ç½‘å…¬å¸æ‹…ä»»UIè®¾è®¡å¸ˆ"),
        ("æœªæ¥è®¡åˆ’", "æˆ‘è®¡åˆ’æ˜å¹´å­¦ä¹ æ‘„å½±")
    ]
    
    print("\næµ‹è¯•äº‹å®æå–åŠŸèƒ½:\n")
    for label, conversation in test_cases:
        print(f"  [{label}]")
        print(f"  å¯¹è¯: {conversation}")
        
        facts = memory.extract_facts(conversation)
        
        if facts:
            print(f"  æå–äº‹å®: {facts}")
        else:
            print("  æå–äº‹å®: (æ— å®è´¨æ€§ä¿¡æ¯)")
        print()
    
    print("âœ… ç¤ºä¾‹4å®Œæˆ")


def example_advanced_search():
    """ç¤ºä¾‹5: é«˜çº§æœç´¢åŠŸèƒ½"""
    print("\n" + "=" * 70)
    print("ğŸ” ç¤ºä¾‹5: é«˜çº§æœç´¢")
    print("=" * 70)
    
    memory = MemorySystem(collection_name="demo_search")
    
    # å‡†å¤‡ä¸°å¯Œçš„è®°å¿†æ•°æ®
    print("\n1ï¸âƒ£ å‡†å¤‡æµ‹è¯•æ•°æ®...")
    knowledge = [
        "æˆ‘åœ¨2020å¹´æ¯•ä¸šäºæ¸…åå¤§å­¦è®¡ç®—æœºç³»",
        "æˆ‘çš„ç¬¬ä¸€ä»½å·¥ä½œæ˜¯åœ¨å­—èŠ‚è·³åŠ¨åšåç«¯å¼€å‘",
        "2022å¹´æˆ‘è·³æ§½åˆ°äº†é˜¿é‡Œå·´å·´",
        "æˆ‘ç°åœ¨è´Ÿè´£ç”µå•†æ¨èç³»ç»Ÿçš„å¼€å‘",
        "æˆ‘æœ€æ“…é•¿çš„æŠ€æœ¯æ ˆæ˜¯Pythonå’ŒGo",
        "ä¸šä½™æ—¶é—´æˆ‘å–œæ¬¢ç ”ç©¶æœºå™¨å­¦ä¹ ç®—æ³•",
        "æˆ‘çš„é•¿æœŸç›®æ ‡æ˜¯æˆä¸ºä¸€åæŠ€æœ¯ä¸“å®¶"
    ]
    
    for k in knowledge:
        memory.write_memory(k, user_id="user_tech", agent_id="assistant")
    
    print(f"âœ… å·²å†™å…¥ {len(knowledge)} æ¡è®°å¿†")
    
    # ä¸åŒç±»å‹çš„æœç´¢
    print("\n2ï¸âƒ£ æ‰§è¡Œä¸åŒç±»å‹çš„æœç´¢...\n")
    
    search_cases = [
        ("æ•™è‚²èƒŒæ™¯", "æ¯•ä¸šé™¢æ ¡"),
        ("å·¥ä½œç»å†", "å·¥ä½œå˜åŠ¨å†å²"),
        ("æŠ€æœ¯èƒ½åŠ›", "æ“…é•¿çš„ç¼–ç¨‹è¯­è¨€"),
        ("å…´è¶£çˆ±å¥½", "ä¸šä½™çˆ±å¥½"),
        ("èŒä¸šè§„åˆ’", "æœªæ¥ç›®æ ‡")
    ]
    
    for category, query in search_cases:
        print(f"  [{category}] æŸ¥è¯¢: {query}")
        results = memory.search_memory(
            query=query,
            user_id="user_tech",
            limit=2
        )
        
        if results:
            for i, r in enumerate(results, 1):
                print(f"    {i}. {r['text']} (åˆ†æ•°: {r['score']:.3f})")
        else:
            print("    æœªæ‰¾åˆ°ç›¸å…³ç»“æœ")
        print()
    
    print("âœ… ç¤ºä¾‹5å®Œæˆ")


if __name__ == "__main__":
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(
        description='TinyMem0 è®°å¿†ç³»ç»Ÿå®Œæ•´ç¤ºä¾‹ - è‡ªåŠ¨ä¸‹è½½æ¨¡å‹å¹¶è¿è¡Œ',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog='''
ç¤ºä¾‹ç”¨æ³•:
  # ä½¿ç”¨é»˜è®¤æ¨¡å‹ (Qwen2.5-7B GGUFæ ¼å¼)
  python examples/complete_demo.py
  
  # æŒ‡å®šå…¶ä»–æ¨¡å‹
  python examples/complete_demo.py --model mistral-7b --format gguf
  python examples/complete_demo.py --model qwen2.5-3b --format safetensors
  
  # è·³è¿‡æ¨¡å‹ä¸‹è½½ï¼ˆä½¿ç”¨äº‘ç«¯APIæˆ–å·²æœ‰æ¨¡å‹ï¼‰
  python examples/complete_demo.py --skip-download

æ”¯æŒçš„æ¨¡å‹:
  qwen2.5-7b, qwen2.5-3b, qwen2.5-1.5b
  mistral-7b, llama3-8b, yi-6b

æ”¯æŒçš„æ ¼å¼:
  gguf       - CPUæ¨ç†ï¼Œ4-8GB (æ¨è)
  safetensors - GPUæ¨ç†ï¼Œ14-26GB
        ''')
    
    parser.add_argument(
        '--model', '-m',
        type=str,
        default='mistral-7b',
        choices=['qwen2.5-7b', 'qwen2.5-3b', 'qwen2.5-1.5b',
                'mistral-7b', 'llama3-8b', 'yi-6b'],
        help='é€‰æ‹©æ¨¡å‹ (é»˜è®¤: mistral-7b, ä½¿ç”¨TheBloke/Mistral-7B-Instruct-v0.2-GGUF)'
    )
    
    parser.add_argument(
        '--format', '-f',
        type=str,
        default='gguf',
        choices=['gguf', 'safetensors'],
        help='æ¨¡å‹æ ¼å¼ (é»˜è®¤: gguf)'
    )
    
    parser.add_argument(
        '--skip-download', '-s',
        action='store_true',
        help='è·³è¿‡æ¨¡å‹ä¸‹è½½ï¼Œç›´æ¥è¿è¡Œdemo'
    )
    
    args = parser.parse_args()
    
    # ä¸‹è½½æ¨¡å‹ï¼ˆé™¤éæ˜ç¡®è·³è¿‡ï¼‰
    if not args.skip_download:
        download_models(args.model, args.format)
        print("\n")
    else:
        print("â­ï¸  è·³è¿‡æ¨¡å‹ä¸‹è½½\n")
    
    # è¿è¡Œä¸»ç¤ºä¾‹
    main()
